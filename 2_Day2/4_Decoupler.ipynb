{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Transcription factor activity with Decoupler\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "We'll start from the previously saved AnnData of metacells that we called <code>3_CellrankAdata.h5ad</code>\n",
    "\n",
    "\n",
    "## Notebook content\n",
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "    <ul>\n",
    "        <li>TF activity computation with Decoupler </li>\n",
    "        <li>TF activity along trajectories - Combining Decoupler and CellRank</li>\n",
    "</ul>\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "Decoupler overview:\n",
    "\n",
    "<div>\n",
    "  <img src=\"https://decoupler-py.readthedocs.io/en/latest/_images/graphical_abstract.png\" width=\"800\">\n",
    "</div>\n",
    "\n",
    "Reference: <a href=\"https://academic.oup.com/bioinformaticsadvances/article/2/1/vbac016/6544613\">decoupleR: ensemble of computational methods to infer biological activities from omics data</a>\n",
    "\n",
    "From the homepage of the <a href=\"https://decoupler-py.readthedocs.io/en/latest/\">Documentation</a>\n",
    "> `decoupler` is a package containing different **statistical methods** to extract biological activities from omics data within a unified framework. It allows to flexibly test any enrichment method with any prior knowledge resource and incorporates methods that take into account the sign and weight.\n",
    "\n",
    "It also wrap many utilities for <a href=\"https://decoupler-py.readthedocs.io/en/latest/notebooks/pseudobulk.html\">pseudobulk analysis</a> , <a href=\"https://decoupler-py.readthedocs.io/en/latest/notebooks/msigdb.html\">functional enrichment and databases access</a>, <a href=\"https://decoupler-py.readthedocs.io/en/latest/notebooks/translate.html\">genes' names conversion</a>\n",
    "\n",
    "Today we will focus on Transcription Factor (TF) activity inference. A tutorial for this can be found <a href=\"https://decoupler-py.readthedocs.io/en/latest/notebooks/dorothea.html\">here</a> \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc, anndata as ad, numpy as np, pandas as pd\n",
    "import warnings\n",
    "import yaml\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scanpy.external as sce\n",
    "import scipy.sparse as sp\n",
    "import statsmodels.api as sm\n",
    "import scanpy as sc\n",
    "import cellrank as cr\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "import matplotlib.pyplot \n",
    "import scanpy.external as sce\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n",
    "import scvelo as scv\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import itertools\n",
    "import decoupler as dc\n",
    "import sys\n",
    "pio.renderers.default = \"jupyterlab\"\n",
    "import random\n",
    "random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homeDir = os.getenv(\"HOME\")\n",
    "\n",
    "sc.settings.verbosity = 3             # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_header()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(1, \"./utils/\")\n",
    "\n",
    "\n",
    "from CleanAdata import *\n",
    "from SankeyOBS import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Metacells Anndata\n",
    "\n",
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "We load here the dataset. If you don't have this AnnData saved in the current folder, uncomment the second line and comment the first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CombinedAdata = sc.read_h5ad(\"./3_CellrankAdata.h5ad\")\n",
    "#CombinedAdata = sc.read_h5ad(\"/group/brainomics/InputData/3_CellrankAdata.h5ad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute TF activity\n",
    "\n",
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "We will compute the transcription factor activity based on the gene expression of their target as imputed by MAGIC, in order to have a more clean signal. Each transcription factor activity will be computed as a <a href=\"https://decoupler-py.readthedocs.io/en/latest/generated/decoupler.run_ulm.html#decoupler.run_ulm\">Univariate Linear Model</a> of the weighted expression of its targets. The targets and its weight are determined by an external source, in our case <a href=\"https://github.com/saezlab/CollecTRI\">CollecTRI</a> but you could use other resources such as <a href=\"https://saezlab.github.io/dorothea/\">Dorothea</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CombinedAdata.X = CombinedAdata.layers[\"MAGIC_imputed_data\"].copy()\n",
    "\n",
    "# Download database of regulons\n",
    "net = dc.get_collectri(organism='human', split_complexes=False)\n",
    "net\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "We run the model, fitting it on each cell's imputed gene expression. The activity will be inferred from the t-value of the slope:\n",
    "\n",
    "<div>\n",
    "  <img src=\"https://decoupler-py.readthedocs.io/en/latest/_images/ulm.png\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.run_ulm(\n",
    "    mat=CombinedAdata,\n",
    "    net=net,use_raw=False, \n",
    "    source='source',\n",
    "    target='target',\n",
    "    weight='weight',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "In the end we'll have a score for each TF in each cell, that will be extracted and stored in a new AnnData using the `get_acts()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = dc.get_acts(CombinedAdata, obsm_key='ulm_estimate')\n",
    "acts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "For each cell type we can compute the \"marker TF\" using the <code>rank_sources_groups()</code> function, a wrapper of the <code>rank_genes_groups()</code> function from Scanpy. We can then inspect the top active TF and the less active TF for each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dc.rank_sources_groups(acts, groupby='AggregatedClass', reference='rest', method='t-test_overestim_var')\n",
    "n_markers = 7\n",
    "source_markers = df.groupby('group').head(n_markers).groupby('group')['names'].apply(lambda x: list(x)).to_dict()\n",
    "source_markers\n",
    "sc.pl.matrixplot(acts, source_markers, 'AggregatedClass', dendrogram=True, standard_scale='var',\n",
    "                 colorbar_title='Z-scaled scores', cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdown = dc.rank_sources_groups(acts, groupby='AggregatedClass', reference='rest', method='t-test_overestim_var')\n",
    "n_markers = 7\n",
    "source_markersDOWN = dfdown.groupby('group').tail(n_markers).groupby('group')['names'].apply(lambda x: list(x)).to_dict()\n",
    "source_markersDOWN\n",
    "sc.pl.matrixplot(acts, source_markersDOWN, 'AggregatedClass', dendrogram=True, standard_scale='var',\n",
    "                 colorbar_title='Z-scaled scores', cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "Let's see these top markers in the draw graph space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UpandDOwnMarkers = {celltype:[source_markersDOWN[celltype][0]]+[source_markers[celltype][0]] for celltype in list(source_markersDOWN.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in UpandDOwnMarkers.keys():\n",
    "    print(k)\n",
    "    sc.pl.draw_graph(acts, color=UpandDOwnMarkers[k], cmap='RdBu_r',  add_outline=True, ncols=2, vmin='p1', vmax='p99', \n",
    "                     title=[\"Top down:{} for {}\".format(UpandDOwnMarkers[k][0], k), \"Top up:{} for {}\".format(UpandDOwnMarkers[k][1], k)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining TF activity with CellRank\n",
    "\n",
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "We load the model that we previously trained to infer the macrostate from our combined kernel of pseudotime (Palantir output), pluripotency score (CytoTrace output) and transcriptional similarity and compute once again the macrostates and fate probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./GPCCA.pickle', 'rb') as file:\n",
    "    g = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.fit(n_states=4, cluster_key=\"AggregatedLabel\")\n",
    "g.plot_macrostates(which=\"all\", basis=\"X_draw_graph_fa\")\n",
    "g.set_initial_states(\"CycProg\")\n",
    "g.set_terminal_states([\"RG_late\", \"SubPlate\",\"OPC_Oligo\"])\n",
    "g.compute_fate_probabilities()\n",
    "g.plot_fate_probabilities(basis=\"X_draw_graph_fa\", same_plot=False, add_outline=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "    \n",
    "Again we can determing trends of expression fitting a GAM model. Here however we will determine trends in TF activity along trajectories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.adata = g.adata[acts.obs_names,0:acts.shape[1]]\n",
    "g.adata.var_names = acts.var_names\n",
    "g.X = acts.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts.uns = g.adata.uns.copy()\n",
    "acts.obsm = g.adata.obsm.copy()\n",
    "acts.obs = g.adata.obs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cr.models.GAMR(acts, n_knots=6, smoothing_penalty=10.0)\n",
    "\n",
    "\n",
    "# compute putative drivers for the Beta trajectory\n",
    "OPC_Oligo_drivers = g.compute_lineage_drivers(lineages=\"OPC_Oligo\")\n",
    "\n",
    "# plot heatmap\n",
    "cr.pl.heatmap(\n",
    "    acts,\n",
    "    model=model,  # use the model from before\n",
    "    lineages=\"OPC_Oligo\",\n",
    "    cluster_key=\"AggregatedLabel\",\n",
    "    show_fate_probabilities=True,\n",
    "    genes=OPC_Oligo_drivers.head(40).index,\n",
    "    time_key=\"palantir_pseudotime\",\n",
    "    figsize=(12, 10),\n",
    "    show_all_genes=True,\n",
    "    weight_threshold=(1e-3, 1e-3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute putative drivers for the Beta trajectory\n",
    "RG_late_drivers = g.compute_lineage_drivers(lineages=\"RG_late\")\n",
    "\n",
    "# plot heatmap\n",
    "cr.pl.heatmap(\n",
    "    acts,\n",
    "    model=model,  # use the model from before\n",
    "    lineages=\"RG_late\",\n",
    "    cluster_key=\"AggregatedLabel\",\n",
    "    show_fate_probabilities=True,\n",
    "    genes=RG_late_drivers.head(40).index,\n",
    "    time_key=\"palantir_pseudotime\",\n",
    "    figsize=(12, 10),\n",
    "    show_all_genes=True,\n",
    "    weight_threshold=(1e-3, 1e-3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute putative drivers for the Beta trajectory\n",
    "SubPlate_drivers = g.compute_lineage_drivers(lineages=\"SubPlate\")\n",
    "\n",
    "# plot heatmap\n",
    "cr.pl.heatmap(\n",
    "    acts,\n",
    "    model=model,  # use the model from before\n",
    "    lineages=\"SubPlate\",\n",
    "    cluster_key=\"AggregatedLabel\",\n",
    "    show_fate_probabilities=True,\n",
    "    genes=SubPlate_drivers.head(40).index,\n",
    "    time_key=\"palantir_pseudotime\",\n",
    "    figsize=(12, 10),\n",
    "    show_all_genes=True,\n",
    "    weight_threshold=(1e-3, 1e-3),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:day3_env] *",
   "language": "python",
   "name": "conda-env-day3_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
