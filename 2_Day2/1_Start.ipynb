{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced preprocessing: multiplets detection and metacells generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description\n",
    "\n",
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "We will use the processed dataset saved from day 1, `Day1_2_TrevinoFiltNormAdata.h5ad`\n",
    "\n",
    "For info on the data:\n",
    "* _**Single cell transcriptomics dataset from paper published by Trevino et al. (Cell 2021) characterizing human fetal cortex at mid-gestation**._)\n",
    "* <a href=\"https://www.cell.com/cell/fulltext/S0092-8674(21)00942-9?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867421009429%3Fshowall%3Dtrue\"> Paper </a> \n",
    "* <a href=\"https://scbrainregulation.su.domains/\">Dataset interactive Viewer </a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "General info:\n",
    "\n",
    "<ul>\n",
    "<li>Samples: <b>human fetal brain cortex at mid-gestation</b> (4 subjects from PCW16 to PCW24)</li>\n",
    "<li>Sequencing method: <b>single cell</b>b RNASequencing (Chromium platform - 10x Genomics)</li>\n",
    "<li>Obtained number of cells: <b>~58,000</b></li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "## Notebook content\n",
    "\n",
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "<ul>\n",
    "<li>Additional QC for robust analysis</li>\n",
    "<li>Multiplets detection</li>\n",
    "<li>Generation of metacells from kNN graph</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc, anndata as ad, numpy as np, pandas as pd\n",
    "import warnings\n",
    "import yaml\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.sparse as sp\n",
    "import statsmodels.api as sm\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import itertools\n",
    "import sys\n",
    "pio.renderers.default = \"jupyterlab\"\n",
    "\n",
    "import random\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homeDir = os.getenv(\"HOME\")\n",
    "\n",
    "sc.settings.verbosity = 3             # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_header()\n",
    "\n",
    "\n",
    "# import user defined functions from the utils folder\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(1, \"./utils/\")\n",
    "\n",
    "from CleanAdata import *\n",
    "from SankeyOBS import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Load\n",
    "\n",
    "\n",
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "<b>NB:</b> modify the data_path value according to what specified by the trainers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/group/brainomics/InputData/'\n",
    "\n",
    "adata = sc.read_h5ad(data_path + 'Day1_2_TrevinoFiltNormAdata.h5ad')\n",
    "\n",
    "# fix formatting for some metadata\n",
    "adata.obs[\"Auth_Assay_formatted\"] = adata.obs.Auth_Assay.str.replace(\" \",\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Additional QCs\n",
    "\n",
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "Here we perform few additional inspections to ensure to avoid technical issues being carried over to the next steps. \n",
    "\n",
    "First we compute again the quality metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mitochondrial genes, \"MT-\" for human, \"Mt-\" for mouse\n",
    "adata.var[\"mt\"] = adata.var_names.str.startswith(\"MT-\")\n",
    "# ribosomal genes\n",
    "adata.var[\"ribo\"] = adata.var_names.str.startswith((\"RPS\", \"RPL\"))\n",
    "\n",
    "sc.pp.calculate_qc_metrics(\n",
    "    adata, qc_vars=[\"mt\", \"ribo\"], inplace=True, log1p=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "Let's inspect previous clustering, original annotation and collapsed annotation on <b>non-integrated</b>b UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(adata, color=[\"cell_class\", \"cell_label\",\"Leiden_Sel\",\"Auth_Batch\"], ncols=3, wspace=.5, size = 35, vmin='p1', vmax='p99', basis = \"X_umap_nocorr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-size: 15px;\"> **What do you observe?**\n",
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "<details>\n",
    "<summary> Hint </summary>\n",
    "We can already observe how some of the original <b>Cell_label</b> appears to be batch-specific e.g., <b>RG_early/Late</b> and Some <b>ExN clusters</b>. Additionally one cluster of annotated <b>InN (Leiden 11)</b> is in between Excitatory and CGE/MGE interneurons\n",
    "\n",
    "</details>\n",
    "\n",
    "Since distances in the UMAP are not meaningful, we can plot the PCA to see if we have similar observations:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca(adata, color=[\"cell_label\",\"Leiden_Sel\"], ncols=4, wspace=.5, size = 50, vmin='p1', vmax='p99')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "Let's have a look at the top markers of cluster 11 with respect to cluster 6 and 8 (well separated InN cells):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(adata, groupby=\"Leiden_Sel\", method=\"wilcoxon\", groups=[\"11\"], reference=\"6\")\n",
    "sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False)\n",
    "sc.tl.rank_genes_groups(adata, groupby=\"Leiden_Sel\", method=\"wilcoxon\", groups=[\"11\"], reference=\"8\")\n",
    "sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "<b>Leiden 11</b>, despite behing classified as an inhibitory neuron cluster, exhibit higher expression of excitatory markers when compared to Leiden 6 and 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Multiplets inspection via scDblFinder\n",
    "\n",
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "Up until now, we never inspected for multiplets in our dataset, for this reason we'll use the well established <a href=\"https://github.com/plger/scDblFinder\"> scDblFinder</a>. The concept behind this tool is a detetection of doublets or multiplets through a two-step approach:\n",
    "\n",
    "* Generation of in silico doublets\n",
    "* kNN classification of initial cells based on the in silico doublets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"https://f1000research.s3.amazonaws.com/manuscripts/77262/f79040af-8539-4e31-863c-57d1c4d2f44b_figure1.gif\" width=\"800\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "scDblFinder may take a while to run, for this reason we saved already its results in a tsv that we can directly load. However this is the code used to produce the output:\n",
    "\n",
    "</div>\n",
    "\n",
    "```import anndata2ri\n",
    "import rpy2.rinterface_lib.callbacks\n",
    "import logging\n",
    "anndata2ri.activate()\n",
    "%load_ext rpy2.ipython\n",
    "rpy2.rinterface_lib.callbacks.logger.setLevel(logging.ERROR)\n",
    "\n",
    "import os\n",
    "from rpy2 import robjects\n",
    "\n",
    "# Set R_HOME and R_LIBS_USER\n",
    "# Set R_HOME and R_LIBS_USER\n",
    "# Set R_HOME and R_LIBS_USER\n",
    "os.environ['R_HOME'] = '/opt/R/4.3.1/lib/R/bin//R'\n",
    "os.environ['R_LIBS_USER'] = '/opt/R/4.3.1/lib/R/library'\n",
    "from rpy2 import robjects\n",
    "custom_lib_paths = \"/opt/R/4.3.1/lib/R/library\"\n",
    "robjects.r(f'.libPaths(c(\"{custom_lib_paths}\", .libPaths()))')\n",
    "\n",
    "\n",
    "# Clean anndata from unnecessary fields\n",
    "# Clean anndata from unnecessary fields\n",
    "# Clean anndata from unnecessary fields\n",
    "\n",
    "sce = adata.copy()\n",
    "sce = sce.copy()\n",
    "sce.obs = sce.obs[[\"Auth_Sample.ID\"]]\n",
    "del sce.layers[\"lognormcounts\"]\n",
    "del sce.obsp\n",
    "sce.layers[\"counts\"] = sce.layers[\"counts\"].astype(np.int32).todense()\n",
    "sce.X = sce.layers[\"counts\"].copy()\n",
    "sce = sce.copy()\n",
    "\n",
    "del sce.obsm\n",
    "del sce.varm\n",
    "del sce.uns\n",
    "sce.var.index.name = None\n",
    "sce.var = sce.var[[\"ensg\"]]\n",
    "# Run doublets detection\n",
    "# Run doublets detection\n",
    "# Run doublets detection\n",
    "\n",
    "sce = anndata2ri.py2rpy(sce)\n",
    "print(sce)\n",
    "scDblFinder = rpy2.robjects.packages.importr('scDblFinder')\n",
    "S4Vectors = rpy2.robjects.packages.importr('S4Vectors')\n",
    "\n",
    "as_data_frame = rpy2.robjects.r['as.data.frame']\n",
    "sce = scDblFinder.scDblFinder(sce, samples=\"Auth_Sample.ID\")\n",
    "\n",
    "# Save doublets info column\n",
    "#sce.obs[\"scDblFinder.class\"].to_csv(\"...\", sep=\"\\t\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improt doublets class information\n",
    "DBLs = pd.read_csv(\"./utils/DoubletsClass.tsv\", delimiter=\"\\t\", index_col=0)\n",
    "adata.obs = pd.concat([adata.obs, DBLs], axis = 1).loc[adata.obs_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(adata, color=[\"scDblFinder.class\",\"Leiden_Sel\"], ncols=3, wspace=.3, size = 35, vmin='p1', vmax='p99', basis = \"X_umap_nocorr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSankey(adata, covs=[\"Leiden_Sel\",\"scDblFinder.class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <div style=\"padding-top: 10px; font-size: 15px;\"> All cells from Leiden 11 were predicted as doublets, therefore we <b>remove them</b>, together with the rest of the scattered doublets </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[~adata.obs[\"Leiden_Sel\"].isin([\"11\"])]\n",
    "adata = adata[adata.obs[\"scDblFinder.class\"].isin([\"singlet\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Additional filtering\n",
    "\n",
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "For downstream analysis we want to be more conservative, so we inspect the relationship between the percentage of mitochondrial genes and the number of genes detected in each cell to identify outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refine filtering\n",
    "\n",
    "sc.pl.scatter(adata, x=\"pct_counts_mt\",y=\"n_genes_by_counts\", size=40, color=\"pct_counts_ribo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "We can see that cells with a low number of genes have higher percentage of mitochondrial and ribosomal genes, so we filter out those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[adata.obs[\"n_genes_by_counts\"] >= 2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Batches inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "\n",
    "An important quality check to perform is to inspect the impact of technical variables of the datasets on the distribution of the cells in lower dimensional space and whether these could be a confounder. Ideally, when preparing an experimental design you want to have a __similar representation__ of your biological samples across batches.\n",
    "\n",
    "For this dataset we have the metadata key __`Auth_Batch`__ that define batches but also divides samples based on post-conceptional week, thus it will be hard to distinguish the batch effect from the biological effect given by the sampling of different time points. This will need to be taken into consideration when interpreting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,len(adata.obs.Auth_Batch.unique()), figsize=(20, 4), dpi=200)\n",
    "for group in enumerate(adata.obs.Auth_Batch.unique()):\n",
    "    SampleIDs = adata.obs.loc[adata.obs.Auth_Batch == group[1],\"Auth_Sample.ID\"].unique().tolist()\n",
    "    axes[group[0]] = sc.pl.embedding(adata, size = 40, add_outline=True,ncols=2, color=[\"Auth_Sample.ID\"],title=\"{} replicates\".format(group[1]),\n",
    "                     groups=SampleIDs, vmin='p1', vmax='p99', show=False, ax=axes[group[0]], basis = \"umap_nocorr\")\n",
    "\n",
    "plt.subplots_adjust(wspace=.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca(adata, color=[\"Auth_Sample.ID\",\"Auth_Batch\",\"Auth_Age\",\"cell_label\",\"Auth_Assay_formatted\"], ncols=3, wspace=.4, size = 50, vmin='p1', vmax='p99')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSankey(adata, covs=[\"Auth_Age\",\"Auth_Batch\",\"Auth_Assay_formatted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 PCA regressors to check variance associated with covariates\n",
    "\n",
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "A useful assessment consists in understanding how much of the variability of the PCA is explained by the covariates (<b>\"Auth_Sample.ID\"</b>,<b>\"Auth_Batch\"</b>,<b>\"Auth_Assay_formatted\"</b>,<b>\"Auth_Age\"</b>,<b>\"cell_label\"</b>). We can use <a href=\"https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html\">Ordinary Least Squares regression</a> on principal component (PC) embeddings and plot the residuals for specific covariates. This will help us understand whether for a specific principal component and a specific covariates, we observe differences across the values of the covariate. This will highlight covariates and batches that may impact the PC and answer the question <b>\"How much technical and biological factors guide the dimensionality reduction?\"</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.formula.api import ols\n",
    "npcs = 6\n",
    "covToTest = [\"Auth_Sample.ID\",\"Auth_Batch\",\"Auth_Assay_formatted\",\"Auth_Age\",\"cell_label\"]\n",
    "\n",
    "def plotResiduals(adata, covToTest, npcs):\n",
    "    PCRegrDict = {}\n",
    "    sns.set_theme(style=\"ticks\")\n",
    "    varianceSummary = pd.DataFrame()\n",
    "    \n",
    "    for i in range(npcs):\n",
    "        \n",
    "        for n,c in enumerate(covToTest):\n",
    "            # format the data\n",
    "            Dummies = pd.get_dummies(adata.obs[c])\n",
    "            PCRegr = (Dummies.T * adata.obsm[\"X_pca\"][:,i].T).T.melt()\n",
    "            PCRegr = PCRegr[PCRegr[\"value\"] != 0]\n",
    "            PCRegr[\"variable\"] = PCRegr[\"variable\"].astype(\"category\")\n",
    "            PCRegr[\"cov\"] = c\n",
    "            PCRegrDict[\"PC:{}_COV:{}\".format(i+1,c)] = PCRegr.copy()\n",
    "            sns.despine(offset=30)\n",
    "            PCRegrModel = pd.get_dummies(PCRegrDict[\"PC:{}_COV:{}\".format(i+1,c)], \"variable\").copy()\n",
    "            \n",
    "            # define the regression formula\n",
    "            formula = \"\".join([\"value ~ \",\" + \".join([\"C(\"+c+\")\" for c in PCRegrModel.columns[1:-1].tolist()])])\n",
    "            \n",
    "            # fit the regression\n",
    "            fit = ols(formula, data=PCRegrModel).fit() \n",
    "            # fit.rsquared_adj\n",
    "            \n",
    "            # get the residuals\n",
    "            PCRegr[\"rsquared_adj\"] = fit.rsquared_adj\n",
    "            PCRegr[\"PC\"] = i\n",
    "            varianceSummary = pd.concat([varianceSummary,PCRegr ], ignore_index=True)\n",
    "            \n",
    "    CovOrder = {i:varianceSummary.drop_duplicates([\"PC\",\"cov\"])[varianceSummary.drop_duplicates([\"PC\",\"cov\"])[\"PC\"] == i].sort_values(\"rsquared_adj\", ascending=False)[\"cov\"].tolist() for i in varianceSummary[\"PC\"].unique().tolist()}\n",
    "    \n",
    "    for i in range(npcs):\n",
    "        fig, axes = plt.subplots(1,len(covToTest), figsize=(40,4), dpi=300, sharex=False,sharey=False)\n",
    "        plt.subplots_adjust(wspace=.5)\n",
    "\t\t#adata.obsm[\"X_pca\"]\n",
    "        \n",
    "        for n,c in enumerate(CovOrder[i]):\n",
    "            PCRegr = varianceSummary[(varianceSummary[\"PC\"] == i) & (varianceSummary[\"cov\"] == c)]\n",
    "            sns.boxplot(data=PCRegr, x=\"variable\", y=\"value\", ax = axes[n],whis=[0, 100],\n",
    "                        palette={i:adata.uns[c+\"_colors\"][adata.obs[c].cat.categories.tolist().index(i)] for i in PCRegr[\"variable\"].unique().tolist()}\n",
    "                        #order=[i for i in PlotOrder[c] if i in PCRegr[\"variable\"].unique().tolist()],\n",
    "                        #hue_order=[i for i in PlotOrder[c] if i in PCRegr[\"variable\"].unique().tolist()])\n",
    "                       )\n",
    "            sns.stripplot(data=PCRegr, x=\"variable\", y=\"value\", size=4, color=\".3\",ax = axes[n], \n",
    "                          #order=[i for i in PlotOrder[c] if i in PCRegr[\"variable\"].unique().tolist()],\n",
    "                          #hue_order=[i for i in PlotOrder[c] if i in PCRegr[\"variable\"].unique().tolist()])\n",
    "                         )\n",
    "            axes[n].title.set_text('Covariate:{}'.format(c))\n",
    "            axes[n].set_xlabel(c, fontsize=20)\n",
    "            axes[n].set_ylabel(\"PC{} embeddings\".format(i+1), fontsize=20)\n",
    "            sns.despine(offset=30)\n",
    "            fit.rsquared_adj = PCRegr[\"rsquared_adj\"].values[0]\n",
    "            axes[n].text(0.5, 0, \"rsquared_adj:{}\".format(round(fit.rsquared_adj,2)), horizontalalignment='center', verticalalignment='center',transform=axes[n].transAxes)\n",
    "            axes[n].tick_params(axis=\"x\", rotation=45)\n",
    "            plt.xticks(rotation=45)\n",
    "            fig.autofmt_xdate(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotResiduals(adata, covToTest, npcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. kNN-based metacells aggregation\n",
    "\n",
    "\n",
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "Metacells can be defined as aggregated clusters of a number of transcriptionally similar cells. This aggregation has several <b>advantages</b>:\n",
    "\n",
    "* Reduced __computational burden__\n",
    "* Reduced __data sparsity__ and improved __signal-to-noise ratio__\n",
    "* Mitigation of __transcriptional spikes(??)__\n",
    "* Do not rely on __previous clustering or annotation__\n",
    "\n",
    "After the aggregation we obtain an object similar to the previous one but with a lower number of cells, each one belonging to a neighbourhood defined by the aggregation method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"https://www.embopress.org/cms/10.1038/s44320-024-00045-6/asset/0950e5e3-eaf9-4448-9016-290de5c5ecc9/assets/graphic/44320_2024_45_fig1_html.png\" width=\"1000\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "The most used methods are <b>Seacells</b> and <b>Metacell2</b>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th>Seacells</th>\n",
    "    <th>Metacell2</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td align=\"center\">\n",
    "      <img src=\"https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41587-023-01716-9/MediaObjects/41587_2023_1716_Fig1_HTML.png?as=webp\" width=\"1000\">\n",
    "      <br>\n",
    "      <a href=\"https://www.nature.com/articles/s41587-023-01716-9\">https://www.nature.com/articles/s41587-023-01716-9</a>\n",
    "    </td>\n",
    "    <td align=\"center\">\n",
    "      <img src=\"https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs13059-022-02667-1/MediaObjects/13059_2022_2667_Fig1_HTML.png?as=webp\" width=\"1000\">\n",
    "      <br>\n",
    "      <a href=\"https://genomebiology.biomedcentral.com/articles/10.1186/s13059-022-02667-1\">https://genomebiology.biomedcentral.com/articles/10.1186/s13059-022-02667-1</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding-top: 10px; font-size: 15px;\">\n",
    "However, in our case we rely on a <b>faster</b> implementation based only on KNN aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(adata.obs.cell_label,adata.obs.cell_class).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's remove non relevant cell types and collapse some others\n",
    "adata = adata[~adata.obs[\"cell_class\"].isin(['Microglia','Other','InN'])]\n",
    "pd.crosstab(adata.obs.cell_label,adata.obs.cell_class).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Metacells definition and aggregation\n",
    "\n",
    "We propose a method that follows these steps:\n",
    "\n",
    "* First of all, before the aggregation, we need to define the kNN graph and its parameter. We can tune it by defining the number of __Highly Variable Genes__ used for __Principal Component Analysis__ and, of those, decide how many will be used to compute the distance between the cells. Since we are computing a kNN, we will need to decide the __number of neighbours (k)__ to which a cell will be connected to.\n",
    "\n",
    "* For __each sample__, we compute the __kNN graph__ with Scanpy's function `sc.pp.neighbors`\n",
    "\n",
    "* The computed connectivities will be used as values to cluster the cells by applying a [__kMeans clustering__ (https://scikit-learn.org/1.5/modules/clustering.html#k-means) and taking the average normalized expression value of each gene in each cluster. We save these values in a new AnnData object, which .X matrix will be metacells x genes and __concatenate the results for all the samples__. Here we set 400 metacells for each sample and we have 6 samples, so we'll have 3200 metacells in the end.\n",
    "\n",
    "* We __assign a label__ to each cluster based on the the most common cell label for each cluster\n",
    "\n",
    "\n",
    "<span style=\"color: red; font-size: 15px;\"> **What impact do you expect to have the change of the initial number of highly variable genes?**\n",
    "\n",
    "<details>\n",
    "<summary> Hints </summary>\n",
    "<dl>\n",
    "<dt>A higher number of highly variable genes will:</dt>\n",
    "    <dd>- increase the computational burden</dd>\n",
    "    <dd>- increase the risk of including genes that are not useful to define differences across cells (ex. genes that are in common to more cell types or are widely expressed)</dd>\n",
    "    <dd>- increase the risk of having metacells driven by technical confounder</dd>\n",
    "        \n",
    "</dl>\n",
    "\n",
    "<dl>\n",
    "<dt>A lower number of highly variable genes will:</dt>\n",
    "    <dd>- decrease the computational burden</dd>\n",
    "    <dd>- increase the risk of excluding useful genes for the definition of a particular cell states</dd>\n",
    "    <dd>- increase the risk of not capturing subtile differences between cell states and having less pure metacells (ex. composed of a mix of cells from different cell states)</dd>\n",
    "</dl>\n",
    "</details>\n",
    "\n",
    "<span style=\"color: red; font-size: 15px;\"> **What impact do you expect to have the change of the initial number of principal components?**\n",
    "\n",
    "<details>\n",
    "<summary> Hints </summary>\n",
    "<dl>\n",
    "<dt>Including a higher number of principal components will:</dt>\n",
    "    <dd>- increase the computational burden</dd>\n",
    "    <dd>- increase the risk of including PC which variance is driven by technical variation</dd>\n",
    "    <dd>- increase the risk of metacells to be representative of a batch and not of the cell states</dd>\n",
    "</dl>\n",
    "\n",
    "<dl>\n",
    "<dt>Including a lower number of principal components will:</dt>\n",
    "    <dd>- decrease the computational burden</dd>\n",
    "    <dd>- increase the risk of excluding biological information</dd>\n",
    "    <dd>- increase the risk of capturing not enough complexity and loosing rarer cell states</dd>\n",
    "</dl>\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewAdataList = []\n",
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "n_neighbors = 30\n",
    "n_pcs = 8\n",
    "n_top_genes = 2000\n",
    "n_clusters = 400\n",
    "\n",
    "\n",
    "for sample in adata.obs[\"Auth_Sample.ID\"].unique().tolist():\n",
    "    adataLocal = adata[adata.obs[\"Auth_Sample.ID\"] == sample].copy()\n",
    "    ncells = adataLocal.shape[0]\n",
    "    filenameBackup = \"./utils/kmeansAggregation/Kmeans{}.{}.{}topgenes.{}neighbs.{}pcs.{}Ks.csv\".format(ncells,sample,n_top_genes,n_neighbors,n_pcs,n_clusters )\n",
    "    \n",
    "    # Check if the kmeans was precomputed\n",
    "    if os.path.isfile(filenameBackup):\n",
    "        print(\"Retrieving precomputed kmeans classes \\n\")\n",
    "        KmeansOBS = pd.read_csv(filenameBackup, sep=\"\\t\", index_col=0)\n",
    "        adataLocal.obs['kmeans_clusters'] = KmeansOBS\n",
    "    else:\n",
    "        #If not run k-means metacells aggregation\n",
    "        sc.pp.highly_variable_genes(adataLocal, n_top_genes=n_top_genes, flavor=\"seurat\")\n",
    "        sc.tl.pca(adataLocal)\n",
    "        # Step 1: Compute the KNN graph\n",
    "        sc.pp.neighbors(adataLocal, n_neighbors = n_neighbors , transformer='pynndescent', n_pcs=n_pcs, metric=\"euclidean\")  # Adjust n_neighbors as needed\n",
    "        # Step 2: Extract the connectivity matrix from AnnData\n",
    "        connectivities = adataLocal.obsp['distances'].toarray()\n",
    "        \n",
    "        # Step 3: Apply K-Means clustering with a fixed number of clusters\n",
    "        print(\"Computing kmeans\")\n",
    "        adataLocal.obs['kmeans_clusters'] = KMeans(n_clusters=n_clusters, random_state=0).fit_predict(connectivities)\n",
    "        print(\"Storing kmeans classes \\n\")\n",
    "        adataLocal.obs[\"kmeans_clusters\"].to_csv(filenameBackup, sep=\"\\t\")\n",
    "\n",
    "    \n",
    "    adataLocal.X = adataLocal.layers[\"counts\"].copy()\n",
    "\n",
    "    # Normalize counts\n",
    "    sc.pp.normalize_total(adataLocal, target_sum=2e4)\n",
    "\n",
    "    # Create combined AnnData objects efficiently and add to NewAdataList\n",
    "    # Step 2: Create dummy variables for clusters\n",
    "    dummy_clusters = pd.get_dummies(adataLocal.obs['kmeans_clusters'])\n",
    "\n",
    "    # Step 3: Dot product for mean aggregation of expression values\n",
    "    # Each column in `cluster_aggregated_X` represents mean expression for a cluster\n",
    "    X_dense = adataLocal.X.A if hasattr(adataLocal.X, \"A\") else adataLocal.X\n",
    "    cluster_aggregated_X = dummy_clusters.T.dot(X_dense)\n",
    "\n",
    "    cluster_aggregated_median_X = np.zeros((dummy_clusters.shape[1], X_dense.shape[1]))\n",
    "    for cluster_idx in range(dummy_clusters.shape[1]):\n",
    "        # Select cells belonging to the current cluster\n",
    "        cluster_cells = X_dense[dummy_clusters.iloc[:, cluster_idx].values == 1]\n",
    "        # Compute the median across cells within the cluster\n",
    "        cluster_aggregated_median_X[cluster_idx, :] = np.median(cluster_cells, axis=0)\n",
    "\n",
    "    # Convert to AnnData structure\n",
    "    adataAggregated = ad.AnnData(X=cluster_aggregated_X)\n",
    "    adataAggregated.layers[\"median\"] = cluster_aggregated_median_X # we save an additional layer having as aggregated value the median of the gene expression\n",
    "    adataAggregated.var_names = adataLocal.var_names\n",
    "    adataAggregated.obs['kmeans_clusters'] = dummy_clusters.columns\n",
    "\n",
    "    # Step 4: Aggregating labels and metadata\n",
    "    # Get the most common cell label for each cluster\n",
    "    adataAggregated.obs['AggregatedClass'] = (\n",
    "        adataLocal.obs.groupby('kmeans_clusters')['cell_class']\n",
    "        .agg(lambda x: x.value_counts().idxmax())\n",
    "        .reindex(dummy_clusters.columns)\n",
    "        .values\n",
    "    )\n",
    "    adataAggregated.obs['AggregatedLabel'] = (\n",
    "        adataLocal.obs.groupby('kmeans_clusters')['cell_label']\n",
    "        .agg(lambda x: x.value_counts().idxmax())\n",
    "        .reindex(dummy_clusters.columns)\n",
    "        .values\n",
    "    )\n",
    "    adataAggregated.obs_names = list(sample+\"_\"+adataAggregated.obs[\"kmeans_clusters\"].astype(str))\n",
    "    # Assign metadata fields with identical values across each cluster\n",
    "    for obsMD in [col for col in adataLocal.obs.columns if len(adataLocal.obs[col].unique()) == 1]:\n",
    "        adataAggregated.obs[obsMD] = adataLocal.obs[obsMD].iloc[0]\n",
    "\n",
    "    # Add the aggregated AnnData to NewAdataList\n",
    "    NewAdataList.append(adataAggregated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new aggregated anndata\n",
    "from scipy import sparse\n",
    "CombinedAdata = ad.concat(NewAdataList)\n",
    "# Conevert to sparse matrix\n",
    "CombinedAdata.X = sparse.csr_matrix(CombinedAdata.X)\n",
    "CombinedAdata.layers[\"median\"] = sparse.csr_matrix(CombinedAdata.layers[\"median\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CombinedAdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CombinedAdata.write_h5ad(\"./1_CombinedMetaCells.h5ad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:day3_env] *",
   "language": "python",
   "name": "conda-env-day3_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
